<h1>MAC - OSX Malware Detection</h1>
<h5>Overview</h5>
<p>The project was completed as part of the course &quot;Methods for Detecting Cyber Attacks&quot; by Dr. Dan Rubin.</p>
<p>You can use a <strong>live demo</strong> of the project <a href='https://d0lev-macmalwaredetection-app-w0wkyg.streamlit.app/'>here</a></p>
<p>To build our dataset, we downloaded 101 examples of normal files from the Apple store and 202 malicious files from around the network. We chose to perform the classification on the Mach-O format files which describe these same runtime files.</p>
<p>&nbsp;</p>
<h2>Data Processing </h2>
<p>You can find the full details in this <a href='https://github.com/d0lev/MacMalwareDetection/blob/master/Preprocessing.ipynb'>notebook</a></p>
<p>We used the LIEF library to parse each Mach-O file into a JSON file, making it easier to extract features. We then recorded each JSON file in a DataFrame where each column corresponded exactly to what appeared in the JSON file.</p>
<p>&nbsp;</p>
<h5>Feature Engineering</h5>
<p>We encountered many categorical variables, which we processed using relatively simple implementations such as label encoder. However, for the list of libraries used by the file, we used the Word2Vec model to study their representation in space.</p>
<p>We performed engineering on the following features:</p>
<ol>
<li><p><strong>libraries names</strong>:  Containing a list of libraries that the files use, we first decomposed the list of libraries into tokens and created a dictionary containing 3272 tokens. Next, we used the Word2Vec model to generate embedding vectors for each token/library per file. In the final stage, we used the PCA algorithm to reduce the dimension while preserving 95% of the variance. The same feature was replaced by 44 columns that describe the values selected from the assimilation vectors of the libraries.</p>
</li>
<li><p><strong>function start functions</strong>: Containing a list of virtual addresses in memory for functions or operations that the file uses, we took each such list and calculated the average distance between each pair of commands in the list.</p>
</li>
<li><p><strong>header flags</strong>: Each file has a header containing a list of flags, which we turned into columns in the dataset where 1 appeared if the flag was present in the file, otherwise 0.</p>
</li>
<li><p><strong>uuid</strong>: Containing a list of numbers that describe in bytes the unique name of the file, we used libraries that extract the unique name from the aforementioned list of bytes.</p>
<p>&nbsp;</p>
</li>

</ol>
<h2>Exploratory Data Analysis</h2>
<p>You can find the full details in this <a href='https://github.com/d0lev/MacMalwareDetection/blob/master/DataExploration.ipynb'>notebook</a></p>
<p>To better understand the data, we conducted several comparisons between the files with malware and those that were not. </p>
<p>Specifically, we analyzed:</p>
<ul>
<li><p>The ratio between the types of libraries that appear in the files.</p>
</li>
<li><p>The comparison of the different sizes between the segments for the two types of files.</p>
</li>
<li><p>Comparison of the average values that describe the number of jumps between the instructions that were carried out in the malicious files and those that were not.</p>
<p>&nbsp;</p>
</li>

</ul>
<h2>Model Training</h2>
<p>You can find the full details in this <a href='https://github.com/d0lev/MacMalwareDetection/blob/master/Modeling.ipynb'>notebook</a></p>
<p>We used XGBoost (XGB) as our machine learning algorithm. Before training the model, we imputed the missing values by calculating the median of each column in the dataset and performed scaling on the same data. Since the dataset was not balanced (201 samples of malware and 101 samples of benign files), we used the SMOTE technique to balance the dataset.</p>
<p>We performed feature selection by the RFE algorithm, resulting in 40 features being selected.</p>
<p>We divided the dataset into 80% training and 20% testing, and After that, we trained the XGB model using the default hyperparameters and achieved an accuracy of 98% on the test set.</p>
<p>&nbsp;</p>
<pre><code> 	     precision recall  f1-score support
Benign    1.00000  0.95652 0.97778    46
Malware   0.96491  1.00000 0.98214    55

accuracy 0.98020
</code></pre>
<p>&nbsp;</p>
<p>&nbsp;</p>
